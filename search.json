[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Additional materials",
    "section": "",
    "text": "Below is the statistical process followed to analyse results from the paper titled\nDivergent responses to training load in Football: Are Generic and Task-specific tools redundant or complementary?\n*Authorship will be updated once peer review process is completed\nThis section will give a brief overview of analytic steps used with reproducible examples:"
  },
  {
    "objectID": "index.html#load-necessary-packages",
    "href": "index.html#load-necessary-packages",
    "title": "Additional materials",
    "section": "Load necessary packages",
    "text": "Load necessary packages\n\nrequire(\"pacman\")\n\nLoading required package: pacman\n\n\nWarning: package 'pacman' was built under R version 4.3.3\n\npacman::p_load(data.table,lme4,mgcv,broom.mixed,mgcv,tidyverse,rmcorr,tidygraph,\n               igraph,ggraph,ggnetwork,stringr,gratia,emmeans,pracma,signal,DHARMa,performance,collapse,ggthemes,univOutl)\n\nWe are unable to give access to complete raw data-sets but have uploaded de-identifed snippets so that the key processes could be replicated."
  },
  {
    "objectID": "index.html#outlier-detection",
    "href": "index.html#outlier-detection",
    "title": "Additional materials",
    "section": "Outlier detection",
    "text": "Outlier detection\nTo ensure data quality while preserving natural variability, we implemented a conservative outlier detection approach based on robust scale estimation (Qn method). Rather than relying on the standard deviation method, which can be heavily influenced by extreme values themselves (Rousseeuw & Croux, 1993).\nThe Qn method works by calculating pairwise differences between observations and selecting a scaled quantile from these differences. This approach has been show to be a robust measure of dispersion that maintains resistance to contamination even when up to 50% of the data contains outliers, making it substantially more reliable than traditional methods in the presence of extreme values (Rousseeuw & Croux, 1993)\nFor each subject and variable combination, we established outlier boundaries by:\nLower bound = Median - (2.75 � Qn scale) Upper bound = Median + (2.75 � Qn scale)\nThe multiplier of 2.75 was deliberately chosen to implement a conservative threshold that retains most natural variability while excluding only the most extreme observations. All observations that were flagged as potential outliers were scrutinized by domain experts to confirm before removal.\nRousseeuw, P. J., & Croux, C. (1993). Alternatives to the Median Absolute Deviation.�Journal of the American Statistical Association,�88(424), 1273–1283. https://doi.org/10.1080/01621459.1993.10476408\nAcross all the variables analysed for future analysis, a range of 7 to 31 (0.91% to 4.13% of total observations for each test) observations were considered flags and subsequently removed prior to analysis."
  },
  {
    "objectID": "index.html#constant-velocity-identification",
    "href": "index.html#constant-velocity-identification",
    "title": "Additional materials",
    "section": "1) Constant Velocity identification",
    "text": "1) Constant Velocity identification\nBelow shows steps used to identify constant velocity during the High-intensity Intermittent-fixed Submaximal Run (HI-IR). Constant velocity was consistent with the method outlined by Garret et al.\n\nphase_det_url &lt;- \"https://raw.githubusercontent.com/R2mu/AdditionalMaterials/main/data_AddMat/phasedetect_examp.csv\"\n\nphase_data &lt;- fread(phase_det_url )\n\nCreate function for detecting phases based on Garrett et a 2019\n\ncatphase_garrett &lt;- function(velocity,acceleration,rn,lowerlimit=-0.4,upperlimit=0.7) {\n  # Find the index of peak acceleration\n  peak_acc_index &lt;- which.max(acceleration)\n  \n  first_index &lt;- which(acceleration[(peak_acc_index + 1):length(acceleration)] &lt;= 0.7)[1]\n  last_index &lt;- which(acceleration[(peak_acc_index + 1):length(acceleration)] &lt;= (-0.4))[1]\n  \n  first_index &lt;- first_index + peak_acc_index\n  last_index  &lt;- peak_acc_index + last_index \n  val=ifelse(velocity&gt;=2&rn*100&gt;=first_index&rn*100&lt;=last_index,\n             \"CV\",\n             ifelse(rn*100&lt;=first_index,\"AP\",\n                    ifelse(rn*100&gt;=last_index,\"DP\",NA)))\n  return(val)\n}\n\n\nphase_examp=phase_data [,vel_poly6 :=round(predict(lm(vel_m.s ~ stats::poly(rn,6)),.SD),4), \n                        by = .(ID)\n                ][,poly_acc := round((vel_poly6-shift(vel_poly6,n = 1))/0.01,3), by=.(ID)\n                ][,phase_ID_garrett:= catphase_garrett(velocity = vel_poly6,\n                                       acceleration =poly_acc,\n                                       rn=rn,\n                                       lowerlimit = (-.4),\n                                       upperlimit = .7),by=.(ID)]\n\n\nrect= phase_examp[phase_ID_garrett==\"CV\",\n         ][,.(start =min(rn),\n              end=max(rn))]\n\n\nggplot(phase_examp,aes(rn,vel_m.s))+\n  annotate(geom = \"rect\",\n           xmin=rect$start,xmax =rect$end,\n           ymin=-Inf,ymax=Inf,fill=\"green\",alpha=.2)+\n  geom_path(aes(y=vel_poly6,col=phase_ID_garrett))+\n  geom_hline(yintercept=c(.7,-0.4))+\n  geom_path(aes(y=poly_acc,col=phase_ID_garrett))+\n  geom_path(phase_examp[phase_ID_garrett==\"CV\",],\n            mapping=aes(rn,acc.up))+\n  annotate(geom = \"text\",x=3.2,y=3,\n           label=\"VT acceleration collected from accelerometer\",\n           hjust=0,family=\"Times\")+\n labs(x=\"Time (s)\", y = bquote(\"Velocity (m\"~\"\\u00B7\"~\"s\"^-1~\")\"),\n      #subtitle = \"Black line represents VT accelerometer data\",\n      title = \"Constant Velocity Phase Detection\")+\n  theme(legend.position = \"top\",\n       text = element_text(family = \"Times\"),\n       panel.background = element_rect(fill = NA),\n       axis.line = element_line(.25,colour=\"black\"))\n\n\n\n\n\n\n\n\nAccelerometer data collected within the CV phase were then used to calculate player load calculations using formula outlined within the manuscript for all three vectors. Vertical accelerometer data was additionally used to calculate the number of steps that were achieved during the constant velocity phase, where the step detection method is outlined below."
  },
  {
    "objectID": "index.html#step-detection-and-normalization-of-high-intensity-intermittent-fixed-submaximal-run-hi-ir",
    "href": "index.html#step-detection-and-normalization-of-high-intensity-intermittent-fixed-submaximal-run-hi-ir",
    "title": "Additional materials",
    "section": "2) Step detection and Normalization of High-intensity Intermittent-fixed Submaximal Run (HI-IR)",
    "text": "2) Step detection and Normalization of High-intensity Intermittent-fixed Submaximal Run (HI-IR)\nPrior to analysis, three trials were excluded from the study due to insufficient data. The exclusion criterion was set at a minimum of 6 steps identified during the constant velocity phase. This threshold was chosen to ensure at least three steps per leg were captured, which we deemed as bare minimum for accurate assessment of the collected parameters during constant velocity (44). Step identification was performed using vertical acceleration peaks from the 100Hz Inertial Measurement Unit (IMU) data. We employed components of a method described by Benson et al. (45), implemented using the pracma package. All identified peaks were visually inspected for each athlete-trial to ensure accuracy.\nAn example of this process is outlined below.\n\n# load data\nSD_url &lt;-  \"https://raw.githubusercontent.com/R2mu/AdditionalMaterials/main/data_AddMat/exampleStepDetection.csv\"\n\nstepDet&lt;-fread(SD_url)\n\n# find peaks algorithm\n# settings chosen were based of visual inspection that most reliable identified peaks in contact across all individuals. \n\nfind_peaks &lt;- function(x,minPeakHeight=1.2) {\n  peak_indices &lt;- pracma::findpeaks(x, \n                                    threshold =0, \n                                    minpeakdistance = 16,\n                                    minpeakheight = minPeakHeight,\n                                    zero = \"+\")[, 2]\n  peak_indicator &lt;- as.integer(seq_along(x) %in% peak_indices) \n  return(peak_indicator)\n}\n\n\n# implementaion of find peaks across three sample players on a smoothed vertical acceleration signal can be seen below \n# Filtering was performed using a 4th order 25 hz low pass butterworth filter\n\nstepDet &lt;- stepDet[,bw.25_acc.up:=round(filtfilt(butter(1,.25,type=\"low\"), acc.up),2),by=.(ID)\n                ][,peak:=find_peaks(bw.25_acc.up,minPeakHeight = 1.2),\n                   by=.(ID)]\n\nVisual representation of step detection. This was performed for each testing occasion to ensure appropriate detection across all players.\n\nggplot(stepDet,aes(time/60,bw.25_acc.up))+\n  geom_path()+\n  geom_point(stepDet[peak==1,],mapping=aes(time/60,bw.25_acc.up),col=\"red\")+\n  facet_wrap(~ID,ncol=1,scales = \"free\",strip.position = \"top\")+\n  ggthemes::theme_tufte()+\n  labs (x= \"time (s)\",y = bquote(~CF-~SMFT~PL[VT]))+\n  ggthemes::geom_rangeframe()\n\n\n\n\n\n\n\n\nThis was then summarised along with other key Player load derived measures to make sure a minimum of 6 steps was used for further analysis. Below is an example of how this was summarized for each player on each testing occasion.\n\nstepDet[peak==1,.(count=.N),by=.(ID)]\n\n     ID count\n1: #ID1    19\n2: #ID2    21\n3: #ID3    19\n\n\n\nNormalization\nAs both duration and velocity of the HI-IRplateau directly influence accumulated accelerometer-vector loads and were observed to vary from week-to-week, an adjusted estimate was developed. Below is an outline of the steps followed.\n\nLoad and split data\n\nHIIR_url &lt;- \"https://raw.githubusercontent.com/R2mu/AdditionalMaterials/main/data_AddMat/HI_IR_data.csv\"\n\n#url\nHIIR_dat&lt;-fread(HIIR_url)[,ID       := as.factor(ID)\n   ][,Season   := as.factor(Season)\n   ][,logVT    := round(log(pl.up_CV_SMF1),3)\n   ][,logAP   := round(log(pl.fwd_CV_SMF1),3)\n   ][,logML  := round(log(pl.side_CV_SMF1),3)]\n\nset.seed(123)  # for reproducibility\n\nsplit &lt;- 0.7\ntrain &lt;- sample(nrow(HIIR_dat), split * nrow(HIIR_dat))\ntest  &lt;- setdiff(1:nrow(HIIR_dat), train)\n\ntrain_data &lt;- HIIR_dat[train, ]\ntest_data  &lt;- HIIR_dat[test, ]\n\n\n\nCreate fully specified model\n\nadj_gam &lt;- gam(pl.up_CV_SMF1~te(mu.vel_CV_SMF1,tm_CV_SMF1)+\n                             s(GH)+\n                             ## random effects matrix below\n                             s(mu.vel_CV_SMF1,ID,bs=\"re\")+\n                             s(Season, ID, bs = \"re\"),\n                           method = \"REML\",\n                   data = train_data)\n\n\nnon_log &lt;-simulateResiduals(adj_gam,n=1000)\n\nplot(non_log,title=\"Initial model response scale\")\n\n\n\n\n\n\n\n\nBased on the above results we will refit with log transformation and also explore a simpler model along with the fully specified model.\n\nadj.VT_null &lt;- gam(log(pl.up_CV_SMF1)~1+\n                             ## random effects matrix below\n                             s(mu.vel_CV_SMF1,ID, bs=\"re\")+\n                             s(Season,ID, bs = \"re\"),\n                           method = \"REML\",\n                   data = train_data)\n\n# simpler RE structure\nadj.VT_sml &lt;- gam(log(pl.up_CV_SMF1)~te(mu.vel_CV_SMF1,tm_CV_SMF1)+\n                             s(GH)+\n                             ## random effects matrix below\n                             s(mu.vel_CV_SMF1,ID, bs=\"re\")+\n                             s(ID, bs=\"re\"),\n                           method = \"REML\",\n                   data = train_data)\n\n# fully specified\nadj.VT_fs &lt;- gam(log(pl.up_CV_SMF1)~te(mu.vel_CV_SMF1,tm_CV_SMF1)+\n                             s(GH)+\n                             ## random effects matrix below\n                             s(mu.vel_CV_SMF1,ID, bs=\"re\")+\n                             s(Season,ID, bs = \"re\"),\n                           method = \"REML\",\n                   data = train_data)\n\n\nsim=DHARMa::simulateResiduals(adj.VT_sml,n=1000)\nplot(sim,title = \"Simple RE structure\")\n\n\n\n\n\n\n\n\n\nsim=DHARMa::simulateResiduals(adj.VT_fs,n=1000)\nplot(sim,title = \"Full RE structure\")\n\n\n\n\n\n\n\n\n\n\nAssess models\n\n#model_performance(adj.VT_fs)\ncompare_performance(adj.VT_null,adj.VT_sml,adj.VT_fs)\n\nSome of the nested models seem to be identical\n\n\n# Comparison of Model Performance Indices\n\nName        | Model |  AIC (weights) | AICc (weights) |  BIC (weights) |    R2 |  RMSE | Sigma\n----------------------------------------------------------------------------------------------\nadj.VT_null |   gam | 1131.0 (&lt;.001) | 1145.3 (&lt;.001) | 1393.2 (&lt;.001) | 0.378 | 0.239 | 0.252\nadj.VT_sml  |   gam |  305.6 (&lt;.001) |  323.7 (&lt;.001) |  598.2 (0.994) | 0.854 | 0.115 | 0.122\nadj.VT_fs   |   gam |  197.2 (&gt;.999) |  234.8 (&gt;.999) |  608.6 (0.006) | 0.883 | 0.100 | 0.109\n\n\nSignificant improvements from the null model to the fully specified are noted above, we which were also assessed on the hold out data below.\n\nmodel_list &lt;- list(\n  null_model = adj.VT_null,\n  sparse_re = adj.VT_sml, # simplified random effects structure\n  full_re = adj.VT_fs # maximal random effects structure\n # acc_AP = log_adj_AP, place holder for acc.fwd\n#  acc_ML = log_adj_ML  place holder for acc.side\n)\n\n\nfor (model_name in names(model_list)) {\n  current_model &lt;- model_list[[model_name]]\n  \ntst_dat = test_data[,preds:=predict(current_model,.SD)\n        ][!is.na(preds),\n        ][,diff_sq := (logVT-preds)^2\n        ]  \n  \nrmse = tst_dat[,.(RMSE=sqrt(mean(diff_sq)))]\n\nprint(paste0(\"test data RMSE for \",model_name,\": \",round(rmse,2)))\n\n} \n\n[1] \"test data RMSE for null_model: 0.25\"\n[1] \"test data RMSE for sparse_re: 0.13\"\n[1] \"test data RMSE for full_re: 0.12\"\n\n\nWhile the full model exhibited a significant dispersion result, potentially indicating some over specification in the random effects structure, the remaining diagnostic measures were satisfactory. Given that our primary focus was on predictive performance and we believe that the full RE structure is more representative of the data at hand we stuck with the full RE model.\nPredicted vs. Observed plot on hold out data\n\nggplot(tst_dat,aes(logVT,preds))+\n  geom_point(pch=21,fill=\"gray80\",size=2)+\n  geom_abline(slope = 1,intercept = 0)+\n  labs(x=bquote(~Measured~PL[VT]),y=bquote(~Predicted~PL[VT]))+\n  theme_tufte()+\n  geom_rangeframe()\n\n\n\n\n\n\n\n\n\n\n\nNormalising fly results\nFirst, we retrained the chosen model on the full data set, this was performed for each acceleration vector from the IMU.\n\nlog_adj_VT_fin &lt;- gam(logVT~te(mu.vel_CV_SMF1,tm_CV_SMF1)+\n                             s(GH)+\n                             ## random effects matrix below\n                             s(ID, mu.vel_CV_SMF1, bs=\"re\")+\n                             s(Season,ID, bs = \"re\"),\n                           method = \"REML\",\n                   data = HIIR_dat)\n\nCreate a reference data.frame with average values\n\nref_data&lt;-copy(HIIR_dat)[,mu.vel_CV_SMF1 := round(mean(mu.vel_CV_SMF1),2)\n       ][,tm_CV_SMF1      := round(mean(tm_CV_SMF1),2)\n       ][,GH              := round(mean(GH),2)\n       ][,.(Season,ID,GH,nsteps_CV_SMF1,mu.vel_CV_SMF1,tm_CV_SMF1)\n      # create reference prediction based of average values\n       ][,refPred_VT     := round(predict.gam(log_adj_VT_fin,.SD),2)\n      # do some data cleaning for merging later\n       ][,setnames(.SD,\"mu.vel_CV_SMF1\",\"mu_vel\")\n       ][,setnames(.SD,\"tm_CV_SMF1\",\"mu_time\")\n       ][,!c(\"GH\",\"nsteps_CV_SMF1\")]\n\nCreate a prediction grid based of observed values for that day\n\nind_pred = HIIR_dat[,.(Season,ID,GH,nsteps_CV_SMF1,\n                           pl.up_CV_SMF1,pl.fwd_CV_SMF1,pl.side_CV_SMF1,\n                           mu.vel_CV_SMF1,tm_CV_SMF1,logVT),\n         # individual prediction: this would be extended fro AP and ML\n                      ][,indPred_VT   := round(predict.gam(log_adj_VT_fin),3)]\n\nJoin with reference prediction for normalisation.\n\nHIIR_adj=join(ind_pred,ref_data,how=\"left\",verbose=0\n       )[,logAdj_pl.VT   := logVT   - (indPred_VT-refPred_VT)]\n\nVisually represent the impact of adjustment on a subset of players\n\nset.seed(13)\n\nrs &lt;- sample(1:49,12,replace = F)\n\nexamp_lng &lt;- HIIR_adj[,.(ID,logVT,logAdj_pl.VT,indPred_VT)\n                    ][,melt.data.table(.SD,id.vars = 1:2)\n                    ][,variable:=ifelse(variable==\"logAdj_pl.VT\",\"Post Adjustment\",\"Pre Adjustment\")\n                    ][ID%in%rs,]\n\n\n\nggplot(examp_lng,aes(logVT,value,col=variable))+\n  geom_point(alpha=.3)+\n  stat_smooth(method = \"lm\",se=F)+\n  labs(x=\"measured VT_acc\",y=\"predicted VT_acc\",title = \"Subset of adjustment example\")+\n  theme_tufte()+\n  facet_wrap(~ID)+\n  theme(panel.background = element_rect(fill = NA))\n\n\n\n\n\n\n\n\nFrom a global perspective we can notice the reduction in variance post adjustment.\n\nHIIR_lng &lt;- HIIR_adj[,.(ID,logVT,logAdj_pl.VT)\n                     ][,melt.data.table(.SD,id.vars = 1)\n                     ][,variable:=ifelse(variable==\"logAdj_pl.VT\",\"Post Adjustment\",\"Pre Adjustment\")]\n\nggplot(HIIR_lng,aes(x=value,y=variable,fill=variable))+\n  stat_summary(fun.data = \"mean_sdl\",\n               geom = \"crossbar\",\n               fun.args = list(mult=1),position = position_nudge(y=.2),\n               width=.1,alpha=.3,\n               show.legend = F)+\n  geom_jitter(pch=21,height = 0.1,alpha=.3,show.legend = F)+\n  labs(x=bquote(PL[VT]), y = NULL)+\n  theme_tufte()+\n  theme(panel.background = element_rect(fill=NA))"
  },
  {
    "objectID": "index.html#cross-correlations",
    "href": "index.html#cross-correlations",
    "title": "Additional materials",
    "section": "3) Cross Correlations",
    "text": "3) Cross Correlations\nThis section will outline how the within participate cross correlations were computed.\nLoad data.\n\ncrossCor_url&lt;-\"https://raw.githubusercontent.com/R2mu/AdditionalMaterials/main/data_AddMat/crossCor_db.csv\"\n\n\nCrossCor_dat&lt;-fread(crossCor_url)[,ID := as.factor(ID)]\n\nVariables to use for cross correlations\n\ntoi &lt;-paste0(\"value_\",c(\"ave_GB\",\n                 \"ConPV_mx\",\"JHIM.mx\",\"FTCT.mx\",\"FZVmx\",\"EccDur.mn\",\"TTPP.mn\",\n                 \"tm_CV_SMF1\",\"mu.vel_CV_SMF1\",\n                 \"logAdj_pl.up\",\"logAdj_pl.fwd\",\"logAdj_pl.side\",\n                 \"HRmu_perc\",\n                 \"pl.up_CV_SMR1\",\"pl.fwd_CV_SMR1\",\"pl.side_CV_SMR1\"))\n\nCompute within participate correlation matrix\n\ncrossCor=rmcorr_mat(participant = as.factor(ID),\n                    variables = toi,\n                    dataset =CrossCor_dat,\n                    CI.level = 0.95)\n\nDo some data cleaning for graphical represent cross correlations\n\ngraphStrt &lt;- crossCor$summary |&gt;\n  mutate(\n    across(c(\"measure1\", \"measure2\"), ~sub(\"^value_\", \"\", .)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"ave_GB\",\"ADD~Strength\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"logAdj_pl.up\",\"HI-IR~PL[V]\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"logAdj_pl.fwd\",\"HI-IR~PL[AP]\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"logAdj_pl.side\",\"HI-IR~PL[ML]\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"mu.vel_CV_SMF1\",\"HI-IR~Vel\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"tm_CV_SMF1\",\"HI-IR~Dur\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"pl.fwd_CV_SMR1\",\"CF-SMFT~PL[AP]\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"pl.up_CV_SMR1\",\"CF-SMFT~PL[V]\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"pl.side_CV_SMR1\",\"CF-SMFT~PL[ML]\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"HRmu_perc\",\"CF-SMFT~HR[ex]\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"TTPP.mn\",\"CMJ~TTPP\",.x)),\n#    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"TTPF.mx\",\"CMJ~TTPF\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"EccDur.mn\",\"CMJ~Ecc~Dur\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"FZVmx\",\"CMJ~F0V\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"FTCT.mx\",\"CMJ~FT:CT\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"JHIM.mx\",\"CMJ~JH\",.x)),\n    across(c(\"measure1\", \"measure2\"), ~ifelse(.x==\"ConPV_mx\",\"CMJ~Con~Vel\",.x)),\n    r = rmcorr.r,  # Keep original r values\n    r_label = ifelse(r &gt; 0 & lowerCI &gt; 0.1 | r &lt; 0 & upperCI &lt; (-0.1), round(r,2), NA)  # Create a new column for labels\n  )\n\nTurn into graph object\n\ngraphCor &lt;-graphStrt|&gt;\n  graph_from_data_frame(directed = FALSE)\n\nPlot network graph\n\nnetworkFig&lt;-  ggraph(graphCor,layout = \"circle\") +\n  geom_edge_link(aes(\n    edge_alpha = abs(r),\n    edge_width = abs(r), \n    color = r,\n    label = ifelse(is.na(r_label),\"\",r_label)),\n    label_size=3,\n    family = \"Times\",\n    lineend = \"round\",linejoin = \"round\"\n  ) +\n  guides(edge_alpha = \"none\", edge_width = \"none\") +\n  scale_edge_colour_gradientn(limits = c(-1, 1), \n                              breaks = c(-1,-.8,-0.5,-0.3,-0.1,0.1,0.3,0.5,0.8,1),\n                              colors = c(\"firebrick2\",\"white\",\"dodgerblue2\"),\n                              name=\"within participant correlation r\") +\n  geom_node_point(color = \"gray70\", size = 5,pch=21) +\n  geom_node_label(aes(label = name,\n                      hjust = ifelse(x &lt; 0, 1, 0),\n                      vjust = ifelse(y &lt; 0, 1,-0.1)),\n                  parse = T,\n                  size = 3.5,\n                  fill = \"white\",\n                  alpha=.2,\n                  family = \"Times\",\n                  label.padding = unit(0.1, \"lines\"),\n                  label.r = unit(0.1, \"lines\")) +\n  theme_graph() +\n  scale_x_continuous(expand = c(0.12,0.12))+\n  theme(legend.position = \"bottom\",\n        text = element_text(family = \"Times\",size = 12),\n        #axis.text = element_text(),\n        legend.title.position = \"bottom\",\n        legend.title = element_text(hjust=.5),\n        legend.key.width = unit(4,units = \"lines\"),  # Adjust overall legend width\n        legend.key.height = unit(0.5, \"lines\"))\n\nnetworkFig\n\n\n\n\n\n\n\n\n\n#ggsave(networkFig,filename=\"networkFig.png\",dpi = 700,\n#       width = 8,height = 7,units = \"in\")"
  },
  {
    "objectID": "index.html#within-athlete-variability-and-dose-response-effects",
    "href": "index.html#within-athlete-variability-and-dose-response-effects",
    "title": "Additional materials",
    "section": "4) Within Athlete variability and Dose response effects",
    "text": "4) Within Athlete variability and Dose response effects\nSee below an example of the process followed for quantifying the within athlete variability and fitting GAM models to assess dose response models.\n\nDVOI_scaled &lt;-paste0(\"Zscr_BT_\",c(\"ave_GB\",\n                          \"JHIM.mx\",\"FZVmx\",\"FTCT.mx\",#\"TTPP.mn\",\n                          \"tm_CV_SMF1\",\"mu.vel_CV_SMF1\",\n                          \"logAdj_pl.up\",\"logAdj_pl.fwd\",\"logAdj_pl.side\",\n                          \"HRmu_perc\",\n                          \"pl.up_CV_SMR1\",\"pl.fwd_CV_SMR1\",\"pl.side_CV_SMR1\"))\n\nDVOI &lt;-paste0(\"value_\",c(\"ave_GB\",\n                         \"JHIM.mx\",\"FZVmx\",\"FTCT.mx\",#\"TTPP.mn\",\n                         \"tm_CV_SMF1\",\"mu.vel_CV_SMF1\",\n                         \"logAdj_pl.up\",\"logAdj_pl.fwd\",\"logAdj_pl.side\",\n                         \"HRmu_perc\",\n                         \"pl.up_CV_SMR1\",\"pl.fwd_CV_SMR1\",\"pl.side_CV_SMR1\"))\n\n\n\ncvte_url&lt;-\"https://raw.githubusercontent.com/R2mu/AdditionalMaterials/main/data_AddMat/modelData.csv\"\n\nCVTE_dat &lt;- fread(cvte_url)[,ID := as.factor(ID)\n                 ][,Season:=as.factor(Season)]\n\n\npacman::p_load(kableExtra,formattable, purrr,marginaleffects)\n\nback_transform_mu &lt;- function(log_mean, log_sd) {\n  # Compute sigma squared\n  sigma_sq &lt;- log_sd^2\n  \n  # Calculate the mean on the original scale\n  mean_original &lt;- exp(log_mean + sigma_sq / 2)\n  \n  return(mean_original)\n}\n\n\n\nback_transform_sd &lt;- function(log_mean, log_sd) {\n  # Compute sigma squared\n  sigma_sq &lt;- log_sd^2\n  \n  # Calculate the mean on the original scale\n  mean_original &lt;- exp(log_mean + sigma_sq / 2)\n  \n  # Calculate the residual SD on the original scale\n  sd_original &lt;- mean_original * sqrt(exp(sigma_sq) - 1)\n  \n  return(sd_original)\n}\n\n  \nCV_TE   &lt;- list()\ncounts  &lt;- list()\nedf     &lt;- list()\ncp      &lt;- list()\nmodperf &lt;- list()\nresid_str  &lt;- list() \nstoreModel &lt;-list()\nre_struc   &lt;- list()\n\n\nfor (i in 1:length(DVOI)) {\n  \n#  i = 1\n \n  DV_OI    = DVOI[i]\n  DV_Zscr  = DVOI_scaled[i]\n\ngetcols =c(\"ID\",\"Season\",\"Week\",DV_OI)\n\ncount_df =CVTE_dat[!is.na(Zscr_WI_TD_acu7),\n][,..getcols\n][!is.na(get(DV_OI)),\n][,.(cnt=.N),by=.(ID,Season)\n][,.(mu_count = mean(cnt),\n     sd_count = sd(cnt),\n     sm_count = sum(cnt),\n     nplayer=.N),by=.(Season)]\n\n\nn1=count_df[1,4][[1]]\nn2=count_df[2,4][[1]]\n\nweighted_avg &lt;- sum(count_df$mu_count * c(n1,n2)) / (n1+n2)\n\npooled_sd &lt;- sqrt(((n1 - 1) * count_df$sd_count[1]^2 + (n2 - 1) * count_df$sd_count[2]^2) / (n1 + n2 - 2))\n\ncounts[[i]]&lt;-data.table(DV=DV_OI,\n                        pooled_mu = weighted_avg,\n                        pooled_sd = pooled_sd)\n\n  # Null linear mixed effects models for TE estimation\n  null_mod = as.formula(paste0(DV_OI,'~1+(Week||ID/Season)'))\n  \n  \n  mer1  = lmer(null_mod,data = CVTE_dat,\n                  control = lmerControl(\n    optimizer = \"Nelder_Mead\"))                       \n  \n  \n  SDgrp = VarCorr(mer1)|&gt;data.frame()|&gt;\n          dplyr::filter(grp==\"ID\")|&gt;\n          pull(sdcor)\n  \n  Resid = VarCorr(mer1)|&gt;data.frame()|&gt;\n          dplyr::filter(grp==\"Residual\")|&gt;\n          pull(sdcor)\n\n\n\n \n# GAM formulation\n# s(Week, ID, bs = \"re\") +\nnull_std = as.formula(paste0(DV_Zscr,'~1+\n             s(ID, bs = \"re\") +               # Random intercept for ID\n             s(Week, ID, bs = \"re\") +         # Random slope for ID\n             s(Week, Season, ID, bs = \"re\")+  # Random slope for Season within ID\n             s(Season, ID, bs = \"re\")')       # Random intercept for Season within ID\n)\n  \n#s(Week, ID, by = Season,bs = \"re\")+ \n#s(Zscr_WI_HIR_17_acu7,bs=\"ts\")+\n\n# GAM model\nform_zscr = as.formula(paste0(DV_Zscr,'~\n             s(Zscr_WI_TD_acu7,bs=\"ts\")+\n             s(Zscr_WI_VHSR_25_acu7,bs=\"ts\")+\n             s(Week,by=Season,bs=\"cs\")+\n             s(ID, bs = \"re\") +               # Random intercept for ID\n             s(Week, ID, bs = \"re\") +         # Random slope for ID\n             s(Week, Season, ID, bs = \"re\")+  # Random slope for Season within ID\n             s(Season, ID, bs = \"re\")')       # Random intercept for Season within ID\n)\n \n \n##       \n # GAM model scaled\ngam_scaled &lt;- bam(form_zscr,     \n                 data = CVTE_dat,\n                 discrete = T,\n                 method = \"fREML\",\n                 select = T)\n\n\n\nstoreModel[[i]]&lt;-gam_scaled\n\nmodperf[[i]]&lt;- model_performance(gam_scaled)|&gt;\n               data.frame()|&gt;\n               dplyr::mutate(DV = DVOI_scaled[i])  \n\n#\"Zscr_WI_HIR_17_acu7\",\nvars &lt;- c(\"Zscr_WI_TD_acu7\",\"Zscr_WI_VHSR_25_acu7\")\n\n# for context against null model \ngam_null &lt;- bam(null_std,\n               data = CVTE_dat,\n               discrete = T,\n               method = \"fREML\")\n\n#extract_vc(gam_null,digits = 3)[,c(1,2,4,5,6)]\n\n## extract GAM summary stats\nsm =summary(gam_scaled)\nedf[[i]]&lt;-sm$s.table|&gt;data.frame()|&gt;\n  tibble::rownames_to_column(\"var\")|&gt;\n  dplyr::mutate(DV = DV_Zscr)\n \n\n# Exatract smooth estimates\ncp[[i]] &lt;- smooth_estimates(gam_scaled,\n                            unconditional = T,\n                            overall_uncertainty = T) |&gt;\n  add_confint(coverage = .95)|&gt;\n  dplyr::filter(!.type==\"Random effect\")|&gt;\n  select(.smooth,.estimate,.lower_ci,.upper_ci,\n         Zscr_WI_TD_acu7,Zscr_WI_VHSR_25_acu7,Week)|&gt;\n  melt(id.vars=1:4)|&gt;\n  mutate(DV = DV_Zscr)|&gt;\n  as.data.table()\n\n#resid[[i]] \nresid&lt;- CVTE_dat[!is.na(get(DV_Zscr))&!is.na(Zscr_WI_TD_acu7),]|&gt;\n  add_partial_residuals(model = gam_scaled)|&gt;\n  mutate(rn=row_number(),DV= DV_Zscr,\n         key =paste0(ID,\"_\",rn))|&gt;\n  select(key,DV,Zscr_WI_TD_acu7,Zscr_WI_VHSR_25_acu7,\n        \"s(Zscr_WI_TD_acu7)\", \"s(Zscr_WI_VHSR_25_acu7)\",\n        \"s(Week):Season2023\",\"s(Week):Season2024\")|&gt;\n    setDT()\n\n\n\nresid_IV &lt;- resid[,1:4\n          ][,melt.data.table(.SD,id.vars=1:2,variable.name = \"IV\",value.name = \"IV_value\")]\n\nresid_DV &lt;- resid[,c(1:2,5:8)\n          ][,melt.data.table(.SD,id.vars=1:2,variable.name = \"function\",value.name = \"DV_value\")]\n\n\nresid_str[[i]]&lt;- join(resid_IV,resid_DV,how=\"left\")\n\n\nmu = mean(CVTE_dat[,get(DV_OI)],na.rm=T)\nsd = sd(CVTE_dat[,get(DV_OI)],na.rm=T)\n\n## clean table\n\nre_struc[[i]] &lt;- broom.mixed::tidy(mer1,effects=\"ran_pars\",\n                 conf.int=T,conf.method=\"profile\")|&gt;\n                 mutate(DV = DV_OI,\n                        Component = c(\n                        \"Between-Season Trajectory (within athlete)\",\n                        \"Between-Season Baseline (within athlete)\", \n                        \"Between-Athlete Trajectory\",\n                        \"Between-Athlete Baseline\",\n                        \"Residual\"))\n\n\nCV_TE[[i]]&lt;-re_struc[[i]]|&gt;\n    dplyr::filter(group==\"Residual\")|&gt;\n  mutate(Ave =  mu,\n         SD  =  sd,\n         Ave = ifelse(grepl(\"logAdj\",DV_OI),\n                      back_transform_mu(mu,sd),Ave),\n         SD =  ifelse(grepl(\"logAdj\",DV_OI), \n               back_transform_sd(mu,sd),SD),\n        Residual_te = Resid,\n        Residual_te = ifelse(grepl(\"logAdj\",DV_OI),\n                        back_transform_sd(mu,Resid),Residual_te),\n        conf.low = ifelse(grepl(\"logAdj\",DV_OI),\n                     back_transform_sd(mu,conf.low),conf.low),\n        conf.high= ifelse(grepl(\"logAdj\",DV_OI),\n                       back_transform_sd(mu,conf.high),conf.high))|&gt;\n  mutate(CV = ifelse(grepl(\"logAdj\",DV_OI),\n               Residual_te/Ave*100,\n               estimate/Ave*100),\n         LL = conf.low/Ave*100,\n         UL = conf.high/Ave*100,\n         Null = performance::rmse(gam_null),\n         Full  = performance::rmse(gam_scaled))\n\n\n\nprint(DVOI[i])\n\n}\n\nleft join: resid_IV[key, DV] 2974/2974 (100%) &lt;m:m&gt; resid_DV[key, DV] 1487/5948 (25%)\n[1] \"value_ave_GB\"\nleft join: resid_IV[key, DV] 1772/1772 (100%) &lt;m:m&gt; resid_DV[key, DV] 886/3544 (25%)\n[1] \"value_JHIM.mx\"\nleft join: resid_IV[key, DV] 1754/1754 (100%) &lt;m:m&gt; resid_DV[key, DV] 877/3508 (25%)\n[1] \"value_FZVmx\"\nleft join: resid_IV[key, DV] 1766/1766 (100%) &lt;m:m&gt; resid_DV[key, DV] 883/3532 (25%)\n[1] \"value_FTCT.mx\"\nleft join: resid_IV[key, DV] 1510/1510 (100%) &lt;m:m&gt; resid_DV[key, DV] 755/3020 (25%)\n[1] \"value_tm_CV_SMF1\"\nleft join: resid_IV[key, DV] 1508/1508 (100%) &lt;m:m&gt; resid_DV[key, DV] 754/3016 (25%)\n[1] \"value_mu.vel_CV_SMF1\"\nleft join: resid_IV[key, DV] 1504/1504 (100%) &lt;m:m&gt; resid_DV[key, DV] 752/3008 (25%)\n[1] \"value_logAdj_pl.up\"\nleft join: resid_IV[key, DV] 1460/1460 (100%) &lt;m:m&gt; resid_DV[key, DV] 730/2920 (25%)\n[1] \"value_logAdj_pl.fwd\"\nleft join: resid_IV[key, DV] 1438/1438 (100%) &lt;m:m&gt; resid_DV[key, DV] 719/2876 (25%)\n[1] \"value_logAdj_pl.side\"\nleft join: resid_IV[key, DV] 1288/1288 (100%) &lt;m:m&gt; resid_DV[key, DV] 644/2576 (25%)\n[1] \"value_HRmu_perc\"\nleft join: resid_IV[key, DV] 1330/1330 (100%) &lt;m:m&gt; resid_DV[key, DV] 665/2660 (25%)\n[1] \"value_pl.up_CV_SMR1\"\nleft join: resid_IV[key, DV] 1320/1320 (100%) &lt;m:m&gt; resid_DV[key, DV] 660/2640 (25%)\n[1] \"value_pl.fwd_CV_SMR1\"\nleft join: resid_IV[key, DV] 1334/1334 (100%) &lt;m:m&gt; resid_DV[key, DV] 667/2668 (25%)\n[1] \"value_pl.side_CV_SMR1\"\n\n\nBreak down of residual variance from random effects (NULL MODEL)\n\nREstruct &lt;- rbindlist(re_struc) |&gt;mutate(DV = case_when(DV==\"value_ave_GB\"~\"Adductor Strength (N)\",\n                        DV==\"value_JHIM.mx\"~\"Jump height (cm)\",\n                        DV==\"value_FZVmx\"~\"Fz at 0v (N)\",\n                        DV==\"value_FTCT.mx\"~\"FT/CT\",\n                       # DV==\"value_TTPP.mn\"~\"TTPP\",\n                        DV==\"value_tm_CV_SMF1\"~\"SMF Duration\",\n                        DV==\"value_mu.vel_CV_SMF1\"~\"SMF Velocity\",\n                        DV==\"value_logAdj_pl.up\"~\"SMF PL.VT\",\n                        DV==\"value_logAdj_pl.fwd\"~\"SMF PL.AP\",\n                        DV==\"value_logAdj_pl.side\"~\"SMF PL.ML\",\n                        DV==\"value_HRmu_perc\"~\"CF-SMFT HR%\",\n                        DV==\"value_pl.up_CV_SMR1\"~\"CF-SMFT PL.VT\",\n                        DV==\"value_pl.fwd_CV_SMR1\"~\"CF-SMFT PL.AP\",\n                        DV==\"value_pl.side_CV_SMR1\"~\"CF-SMFT PL.ML\"\n                        ))|&gt;\n  mutate(Test = ifelse(grepl(\"CF\",DV),\"CF-SMF\",\n                       ifelse(grepl(\"SMF\",DV),\"SMF\",\n                       ifelse(grepl(\"Adductor\",DV),\"Groin Bar\",\"CMJ\"))))|&gt;\n  dplyr::group_by(DV)|&gt;\n  mutate(sumVar = sum(estimate))|&gt;\n  dplyr::ungroup()|&gt;\n  mutate(contribution = estimate/sumVar*100)\n\nggplot(REstruct,aes(Component,DV,fill=contribution,label=round(estimate,1)))+\n  geom_tile(col=\"white\")+\n  geom_text(col=\"white\",size=3)+\n  facet_grid(Test~Component,scales = \"free\",space = \"free\",\n             labeller = label_wrap_gen(multi_line = T,width = 10))+\n  theme(strip.text = element_text(size=7,face = \"bold\"),\n        axis.text.x = element_blank())\n\n\n\n\n\n\n\n\n\nBetween-Athlete Baseline: How much athletes differ from each other in their overall score. e.g. the between athlete SD across athletes for Jump height is 4.2cm\nBetween athlete Trajectory: How much athletes differ from each other in their rate of change over the season.\nBetween-Season baseline (within athlete): How much an individuals average performance varies between seasons.\nBetween-Season trajectory (within athlete): How much an individual rate of change varies between seasons.\nResidual: Remaining variation within an athlete-season after accounting for all other patterns (within-subject variability)\n\nCreate example of Table 1.\n\npacman::p_load(kableExtra)\n\n rbindlist(CV_TE)|&gt; \n  mutate_if(is.numeric, round,2)|&gt;\n  select(DV,Ave,SD,Residual_te,conf.low,conf.high,CV,LL,UL,Null,Full)|&gt;\n  mutate(DV = case_when(DV==\"value_ave_GB\"~\"Adductor Strength (N)\",\n                        DV==\"value_JHIM.mx\"~\"Jump height (cm)\",\n                        DV==\"value_FZVmx\"~\"Fz at 0v (N)\",\n                        DV==\"value_FTCT.mx\"~\"FT/CT\",\n                       # DV==\"value_TTPP.mn\"~\"TTPP\",\n                        DV==\"value_tm_CV_SMF1\"~\"SMF Duration\",\n                        DV==\"value_mu.vel_CV_SMF1\"~\"SMF Velocity\",\n                        DV==\"value_logAdj_pl.up\"~\"SMF PL.VT\",\n                        DV==\"value_logAdj_pl.fwd\"~\"SMF PL.AP\",\n                        DV==\"value_logAdj_pl.side\"~\"SMF PL.ML\",\n                        DV==\"value_HRmu_perc\"~\"CF-SMFT HR%\",\n                        DV==\"value_pl.up_CV_SMR1\"~\"CF-SMFT PL.VT\",\n                        DV==\"value_pl.fwd_CV_SMR1\"~\"CF-SMFT PL.AP\",\n                        DV==\"value_pl.side_CV_SMR1\"~\"CF-SMFT PL.ML\"\n                        ))|&gt;\n  kableExtra::kable()|&gt;\n    add_header_above(c(\" \",\"Descriptive\" = 2, \"residual SD/TE\" = 3,\n                       \"CV%\" = 3,\"RMSE\" = 2))|&gt;\n  pack_rows(\"Groin Bar\", 1,1) |&gt;\n  pack_rows(\"CMJ\", 2, 4) |&gt;\n  pack_rows(\"HI-IR assessment\", 5, 9) |&gt;\n  pack_rows(\"CF-SMFT assessment\",10, 13) |&gt;\n  kable_paper()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive\n\n\nresidual SD/TE\n\n\nCV%\n\n\nRMSE\n\n\n\nDV\nAve\nSD\nResidual_te\nconf.low\nconf.high\nCV\nLL\nUL\nNull\nFull\n\n\n\n\nGroin Bar\n\n\nAdductor Strength (N)\n478.48\n82.58\n30.75\n29.61\n31.96\n6.43\n6.19\n6.68\n0.36\n0.36\n\n\nCMJ\n\n\nJump height (cm)\n37.73\n4.44\n1.61\n1.53\n1.70\n4.27\n4.07\n4.50\n0.36\n0.31\n\n\nFz at 0v (N)\n2389.43\n456.87\n129.43\n123.03\n136.42\n5.42\n5.15\n5.71\n0.27\n0.26\n\n\nFT/CT\n0.91\n0.16\n0.06\n0.06\n0.06\n6.57\n6.24\n6.92\n0.35\n0.33\n\n\nHI-IR assessment\n\n\nSMF Duration\n4.13\n1.33\n1.20\n1.14\n1.27\n29.17\n27.74\n30.73\n0.85\n0.69\n\n\nSMF Velocity\n24.93\n2.59\n2.30\n2.18\n2.42\n9.22\n8.75\n9.72\n0.87\n0.62\n\n\nSMF PL.VT\n2.49\n0.50\n0.24\n0.23\n0.26\n9.77\n9.25\n10.34\n0.50\n0.48\n\n\nSMF PL.AP\n1.45\n0.27\n0.18\n0.17\n0.19\n12.28\n11.55\n12.92\n0.63\n0.62\n\n\nSMF PL.ML\n1.44\n0.27\n0.18\n0.17\n0.19\n12.69\n12.01\n13.43\n0.65\n0.64\n\n\nCF-SMFT assessment\n\n\nCF-SMFT HR%\n76.36\n4.43\n2.63\n2.48\n2.80\n3.45\n3.25\n3.66\n0.55\n0.50\n\n\nCF-SMFT PL.VT\n19.65\n3.46\n1.67\n1.58\n1.78\n8.50\n8.02\n9.04\n0.52\n0.48\n\n\nCF-SMFT PL.AP\n9.19\n1.65\n0.97\n0.92\n1.03\n10.61\n10.02\n11.26\n0.55\n0.49\n\n\nCF-SMFT PL.ML\n8.96\n1.96\n1.03\n0.97\n1.10\n11.53\n10.86\n12.27\n0.57\n0.53\n\n\n\n\n\n\n  #kableExtra::kable_styling(bootstrap_options = c(\"hover\"))\n\nGAM summary table merged paramater effect\n\nedf_bind &lt;- rbindlist(edf)|&gt;\n        mutate_if(is.numeric, round,3)|&gt;\n        select(DV,var,edf,F,p.value)|&gt;\n        dplyr::filter(!var==\"s(ID)\"&!var==\"s(Season,ID)\")|&gt;\n        dplyr::rename(contrast=var)|&gt;\n        dplyr::rename(edf_pvalue=p.value)|&gt;\n        dplyr::mutate(contrast =  str_extract(contrast, \"(?&lt;=\\\\().*(?=\\\\))\"))|&gt;\n        setDT()\n\n\nvars &lt;- c(\"s(Zscr_WI_TD_acu7)\", \"s(Zscr_WI_VHSR_25_acu7)\")\n\nrng =rbindlist(cp)[!is.na(.estimate),\n       ][.smooth%in%vars,\n       ][!is.na(value),\n       ][,comb:=paste0(DV,\"_\",variable)\n      # calculate maximum observed effect over smoothed range\n       ][,zero:= ifelse(.lower_ci&lt;=0&.upper_ci&gt;=0,0,1)  \n       ][,.(min=round(min(.estimate),2),\n             max=round(max(.estimate),2),\n            CL_overlap=max(zero)),by=.(DV,variable)\n       ][,CL_overlap:=ifelse(CL_overlap==1,\"No\",\"Yes\")\n       ][,range:=max-min\n       ][,.(DV,variable,range,CL_overlap)\n       ][,setnames(.SD,\"variable\",\"contrast\")]\n\n\n# Show key variables who had signficant edf pvalue and effect size &gt;0.3\njoined &lt;- join(edf_bind,rng)|&gt;\n    fsubset(!grepl(\"Week\",contrast))|&gt;\n    fsubset(edf_pvalue&lt;0.01)#&range&gt;=.3)\n\nleft join: edf_bind[DV, contrast] 26/78 (33.3%) &lt;m:m&gt; rng[DV, contrast] 26/26 (100%)\n\n#joined\n# Show table\njoined|&gt;\n  mutate(DV = case_when(DV==\"Zscr_BT_ave_GB\"~\"Adductor Strength (N)\",\n                       DV==\"Zscr_BT_JHIM.mx\"~\"Jump height (cm)\",\n                       DV==\"Zscr_BT_FZVmx\"~\"Fz at 0v (N)\",\n                       DV==\"Zscr_BT_FTCT.mx\"~\"FT/CT\",\n                       DV==\"Zscr_BT_TTPP.mn\"~\"TTPP\",\n                       DV==\"Zscr_BT_tm_CV_SMF1\"~\"SMF Duration\",\n                       DV==\"Zscr_BT_mu.vel_CV_SMF1\"~\"SMF Velocity\",\n                       DV==\"Zscr_BT_logAdj_pl.up\"~\"SMF PL.VT\",\n                       DV==\"Zscr_BT_logAdj_pl.fwd\"~\"SMF PL.AP\",\n                       DV==\"Zscr_BT_logAdj_pl.side\"~\"SMF PL.ML\",\n                       DV==\"Zscr_BT_HRmu_perc\"~\"CF-SMFT HR%\",\n                       DV==\"Zscr_BT_pl.up_CV_SMR1\"~\"CF-SMFT PL.VT\",\n                       DV==\"Zscr_BT_pl.fwd_CV_SMR1\"~\"CF-SMFT PL.AP\",\n                       DV==\"Zscr_BT_pl.side_CV_SMR1\"~\"CF-SMFT PL.ML\"\n                       ),\n         edf = round(edf,1),\n         F = round(F,2))|&gt;\n    kableExtra::kable()|&gt;\n      add_header_above(c(\"\",\"\",\"gam summary\" = 3, \"effect\"=2))|&gt;\n  kable_paper()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngam summary\n\n\neffect\n\n\n\nDV\ncontrast\nedf\nF\nedf_pvalue\nrange\nCL_overlap\n\n\n\n\nJump height (cm)\nZscr_WI_TD_acu7\n1.0\n15.68\n0.000\n0.26\nNo\n\n\nFz at 0v (N)\nZscr_WI_TD_acu7\n4.9\n20.81\n0.003\n0.26\nYes\n\n\nSMF Velocity\nZscr_WI_VHSR_25_acu7\n0.9\n1.33\n0.003\n0.47\nYes\n\n\nCF-SMFT HR%\nZscr_WI_TD_acu7\n1.2\n13.50\n0.000\n0.72\nNo\n\n\nCF-SMFT PL.AP\nZscr_WI_TD_acu7\n2.8\n4.62\n0.000\n0.62\nNo\n\n\nCF-SMFT PL.ML\nZscr_WI_TD_acu7\n2.9\n5.23\n0.000\n0.77\nNo\n\n\n\n\n\n\n\n|\nClean data for plotting\nKey to filter for key variable\n\nrm  &lt;- paste0(joined$DV,\"_\",joined$contrast)\nstr &lt;- paste(rm, collapse = \"','\")\nstr &lt;- paste0(\"c('\", str, \"')\")\n\nCreate plotting data.frame\n\npltDat&lt;- rbindlist(cp)[,comb:= paste0(DV,\"_\",variable)\n                     #][comb%in%eval(parse(text = str)),\n                     ][,DV:=sub(\"^Zscr_BT_\", \"\", DV)\n                     ][,DV:=fcase(DV == \"ave_GB\",\"~Adductor~Strength\",\n                                  DV== \"FZVmx\",\"CMJ~F0V\",\n                                  DV== \"FTCT.mx\",\"CMJ~FT:CT\",\n                                  DV== \"TTPP.mn\",\"CMJ~TTPP\",\n                                  DV== \"JHIM.mx\",\"CMJ~JH\",\n                                  DV== \"mu.vel_CV_SMF1\",\"HI-IR~Vel\",\n                                  DV== \"tm_CV_SMF1\",\"HI-IR~Dur\",\n                                  DV== \"logAdj_pl.up\",\"HI-IR~PL[VT]\",\n                                  DV== \"logAdj_pl.fwd\",\"HI-IR~PL[AP]\",\n                                  DV== \"logAdj_pl.side\",\"HI-IR~PL[ML]\",\n                                  DV== \"HRmu_perc\",\"CF-SMFT~HR[ex]\",\n                                  DV== \"pl.up_CV_SMR1\",\"CF-SMFT~PL[V]\",\n                                  DV== \"pl.fwd_CV_SMR1\",\"CF-SMFT~PL[AP]\",\n                                  DV== \"pl.side_CV_SMR1\",\"CF-SMFT~PL[ML]\")\n              # Dropped below for the sake of a 3*4 grid\n                ][!DV==\"HI-IR~Dur\",\n                ][,variable:=ifelse(variable==\"Zscr_WI_TD_acu7\",\"~7~day~TD\",\n                             ifelse(variable==\"Zscr_WI_VHSR_25_acu7\",\"7~day~VHSR\",\"Week\")\n                             )]\n\n                \npltDat$variable&lt;-fct_relevel(pltDat$variable, \"~7~day~TD\",\n                             \"7~day~VHSR\",\n                             \"Week\")\n\n\nvars &lt;- c(\"s(Zscr_WI_TD_acu7)\", \"s(Zscr_WI_VHSR_25_acu7)\")\n\nresiduals &lt;-rbindlist(resid_str)[,comb:= paste0(DV,\"_\",IV)\n                    #  ][comb%in%eval(parse(text = str)),\n                      ][,DV:=sub(\"^Zscr_BT_\", \"\", DV)\n                      ][,variable:=ifelse(IV==\"Zscr_WI_TD_acu7\",\"~7~day~TD\",\n                             ifelse(IV==\"Zscr_WI_VHSR_25_acu7\",\"7~day~VHSR\",\"Week\"))\n                     ][,DV:=fcase(DV == \"ave_GB\",\"~Adductor~Strength\",\n                                  DV== \"FZVmx\",\"CMJ~F0V\",\n                                  DV== \"FTCT.mx\",\"CMJ~FT:CT\",\n                                  DV== \"TTPP.mn\",\"CMJ~TTPP\",\n                                  DV== \"JHIM.mx\",\"CMJ~JH\",\n                                  DV== \"mu.vel_CV_SMF1\",\"HI-IR~Vel\",\n                                  DV== \"tm_CV_SMF1\",\"HI-IR~Dur\",\n                                  DV== \"logAdj_pl.up\",\"HI-IR~PL[VT]\",\n                                  DV== \"logAdj_pl.fwd\",\"HI-IR~PL[AP]\",\n                                  DV== \"logAdj_pl.side\",\"HI-IR~PL[ML]\",\n                                  DV== \"HRmu_perc\",\"CF-SMFT~HR[ex]\",\n                                  DV== \"pl.up_CV_SMR1\",\"CF-SMFT~PL[V]\",\n                                  DV== \"pl.fwd_CV_SMR1\",\"CF-SMFT~PL[AP]\",\n                                  DV== \"pl.side_CV_SMR1\",\"CF-SMFT~PL[ML]\")\n              # Dropped below for the sake of a 3*4 grid\n                ][!DV==\"HI-IR~Dur\",]\n  \n       \n\n                \nresiduals$variable&lt;-fct_relevel(residuals$variable, \"~7~day~TD\", \n                             \"7~day~VHSR\",\n                             \"Week\")\n\nWarning: 1 unknown level in `f`: Week\n\n\nExamine mean centered PDP/ Recreate effects figure1\n\nlibrary(ggalt)\n\nRegistered S3 methods overwritten by 'ggalt':\n  method                  from   \n  grid.draw.absoluteGrob  ggplot2\n  grobHeight.absoluteGrob ggplot2\n  grobWidth.absoluteGrob  ggplot2\n  grobX.absoluteGrob      ggplot2\n  grobY.absoluteGrob      ggplot2\n\npdpsum&lt;-ggplot()+\n      annotate(geom = \"rect\",fill=\"gray80\",xmin=-Inf,xmax = Inf,\n               ymin = -0.3,ymax=.3,\n           alpha=.3)+\n  geom_hline(yintercept = c(0),lwd=.25)+\n # geom_hline(yintercept = c(-.6,0.6),linetype=\"dashed\")+\n  #geom_vline(xintercept = c(-2,-1,1,2),lwd=.25,alpha=.1)+\n  geom_vline(xintercept = c(0),lwd=.25,alpha=.9)+\n  geom_point(data = residuals[comb%in%eval(parse(text = str)),],alpha=.4,size=1,\n           mapping = aes(x=IV_value,y=DV_value),\n           colour=\"#4e94ce\")+\n  geom_ribbon(pltDat[comb%in%eval(parse(text = str)),],\n              mapping=aes(value,ymin=.lower_ci,ymax=.upper_ci),\n              col=NA,alpha=.3)+\n  geom_path(pltDat[comb%in%eval(parse(text = str)),],mapping=aes(value,y=.estimate))+\n  # facet_grid(variable~DV,labeller =labeller(.default = label_parsed,\n  #     .multi_line = TRUE))+\n  facet_wrap(~DV+variable,nrow=1,\n             labeller = label_parsed)+\n  scale_x_continuous(limits = c(-3,3),breaks = c(-3,-2,-1,0,1,2,3))+\n  scale_y_continuous(limits = c(-2.4,2.4),\n                     breaks = c(-2,-1.2,-.6,-.3,0,0.3,0.6,1.2,2))+\n     theme_tufte()+\n  labs(y=\"Between athlete scaled response\",x=\"Within athlete scaled load\")+\n  theme(panel.background = element_rect(fill = NA,colour = \"black\"))\n\npdpsum\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 300 rows containing missing values or values outside the scale range\n(`geom_path()`).\n\n\n\n\n\n\n\n\n#ggsave(pdpsum,width = 9,height = 3.2,filename=\"pdpsummaryIPsml_upd.png\",dpi=800)\n\nPost Hoc analysis\n\n## SMFT observed effects\n\nsmft_hr=storeModel[[10]] |&gt; \n  emmeans( consec~ Zscr_WI_TD_acu7, \n           var =\"Zscr_WI_TD_acu7\",\n           at = list(\"Zscr_WI_TD_acu7\" = c(-2,0)),\n           cov.reduce=F)|&gt;summary(infer=T)\n#smft_hr$contrasts|&gt;clipr::write_clip()\n#smft_hr$emmeans|&gt;clipr::write_clip()\n\n\n## CF-SMFT PL AP\n\n#rise phase\nsmft_plup=storeModel[[12]] |&gt; \n  emmeans(consec~ Zscr_WI_TD_acu7, \n           var =\"Zscr_WI_TD_acu7\",\n           at = list(\"Zscr_WI_TD_acu7\" = c(-2,0)),\n           cov.reduce=F)|&gt;summary(infer=T)\n\n#smft_plup$contrasts|&gt;clipr::write_clip()\nsmft_plup$emmeans\n\n Zscr_WI_TD_acu7 emmean    SE  df lower.CL upper.CL t.ratio p.value\n              -2 -0.299 0.165 557  -0.6233   0.0256  -1.809  0.0710\n               0  0.145 0.119 557  -0.0897   0.3788   1.212  0.2259\n\nResults are averaged over the levels of: Week, Season \nConfidence level used: 0.95 \n\n#plateau phase\nsmft_plup=storeModel[[12]] |&gt; \n  emmeans(consec~ Zscr_WI_TD_acu7, \n           var =\"Zscr_WI_TD_acu7\",\n           at = list(\"Zscr_WI_TD_acu7\" = c(0,2)),\n           cov.reduce=F)|&gt;summary(infer=T)\n\n#smft_plup$contrasts|&gt;clipr::write_clip()\nsmft_plup$emmeans\n\n Zscr_WI_TD_acu7   emmean    SE  df lower.CL upper.CL t.ratio p.value\n               0  0.14458 0.119 557  -0.0897    0.379   1.212  0.2259\n               2 -0.00603 0.160 557  -0.3197    0.308  -0.038  0.9699\n\nResults are averaged over the levels of: Week, Season \nConfidence level used: 0.95 \n\n\n\n## CF-SMFT PL ML\n\n#rise phase\nsmft_plup=storeModel[[13]] |&gt; \n  emmeans(consec~ Zscr_WI_TD_acu7, \n           var =\"Zscr_WI_TD_acu7\",\n           at = list(\"Zscr_WI_TD_acu7\" = c(-2,0)),\n           cov.reduce=F)|&gt;summary(infer=T)\n\n#smft_plup$contrasts|&gt;clipr::write_clip()\nsmft_plup$emmeans\n\n Zscr_WI_TD_acu7  emmean    SE  df lower.CL upper.CL t.ratio p.value\n              -2 -0.5710 0.162 578   -0.889   -0.253  -3.522  0.0005\n               0 -0.0398 0.112 578   -0.260    0.180  -0.355  0.7226\n\nResults are averaged over the levels of: Week, Season \nConfidence level used: 0.95 \n\n#plateau phase\nsmft_plup=storeModel[[13]] |&gt; \n  emmeans(consec~ Zscr_WI_TD_acu7, \n           var =\"Zscr_WI_TD_acu7\",\n           at = list(\"Zscr_WI_TD_acu7\" = c(0,2)),\n           cov.reduce=F)|&gt;summary(infer=T)\n\n#smft_plup$contrasts|&gt;clipr::write_clip()\nsmft_plup$emmeans\n\n Zscr_WI_TD_acu7  emmean    SE  df lower.CL upper.CL t.ratio p.value\n               0 -0.0398 0.112 578   -0.260   0.1802  -0.355  0.7226\n               2 -0.2277 0.159 578   -0.541   0.0853  -1.429  0.1536\n\nResults are averaged over the levels of: Week, Season \nConfidence level used: 0.95 \n\n\n\n## HIIR effects\n\nhiir_vel=storeModel[[6]] |&gt; \n  emmeans(consec~ Zscr_WI_VHSR_25_acu7, \n           var =\"Zscr_WI_VHSR_25_acu7\",\n           at = list(\"Zscr_WI_VHSR_25_acu7\" = c(-2,0)),\n           cov.reduce=F)|&gt;summary(infer=T)\n\n#hiir_vel$contrasts|&gt;clipr::write_clip()\n\nGroin bar effects\n\nggplot()+\n      geom_hline(yintercept = c(-0.3,0.3),linetype=\"dashed\",col=\"gray70\")+\n    geom_hline(yintercept = 0,col=\"gray7\")+\n    geom_vline(xintercept = c(-1,1),linetype=\"dashed\",col=\"gray70\")+\n    geom_vline(xintercept = 0,linetype=\"dashed\",col=\"gray7\")+\n    geom_point(data = residuals[grepl(\"Adductor\",DV)&!variable==\"Week\",],alpha=.4,size=1,\n           mapping = aes(x=IV_value,y=DV_value),\n           colour=\"#4e94ce\")+\n    geom_ribbon(pltDat[grepl(\"Adductor\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate,ymin=.lower_ci,ymax=.upper_ci),\n       alpha=.5,col=NA)+\n    geom_path(pltDat[grepl(\"Adductor\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate))+\n    facet_grid(rows = vars(DV),cols = vars(variable),\n             labeller = label_parsed)+\n   #  facet_wrap(~DV+variable,nrow=3,\n  #           labeller = label_parsed)+\n   # theme_tufte()+\n    ylim(c(-1.2,1.2))+\n    labs(x = \"Within participant scaled load\",\n       y = \"Between participant scaled response\")+\n    theme(legend.position = \"bottom\",\n          text=element_text(family = \"Times\"),\n          panel.grid = element_blank(),\n        panel.background = element_rect(fill = NA,colour=\"gray30\"))\n\n\n\n\n\n\n\n\nCMJ dose response effects\nCMJ dose response\n\nggplot()+\n      geom_hline(yintercept = c(-0.3,0.3),linetype=\"dashed\",col=\"gray70\")+\n    geom_hline(yintercept = 0,col=\"gray7\")+\n    geom_vline(xintercept = c(-1,1),linetype=\"dashed\",col=\"gray70\")+\n    geom_vline(xintercept = 0,linetype=\"dashed\",col=\"gray7\")+\n    geom_point(data = residuals[grepl(\"CMJ\",DV)&!variable==\"Week\",],alpha=.4,size=1,\n           mapping = aes(x=IV_value,y=DV_value),\n           colour=\"#4e94ce\")+\n    geom_ribbon(pltDat[grepl(\"CMJ\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate,ymin=.lower_ci,ymax=.upper_ci),\n       alpha=.5,col=NA)+\n    geom_path(pltDat[grepl(\"CMJ\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate))+\n  facet_grid(rows = vars(DV),cols = vars(variable),\n             labeller = label_parsed,scale=\"free\")+\n   #  facet_wrap(~DV+variable,nrow=3,\n  #           labeller = label_parsed)+\n   # theme_tufte()+\n    ylim(c(-1.2,1.2))+\n    labs(x = \"Within participant scaled load\",\n       y = \"Between participant scaled response\")+\n    theme(legend.position = \"bottom\",\n          text=element_text(family = \"Times\"),\n          panel.grid = element_blank(),\n        panel.background = element_rect(fill = NA,colour=\"gray30\"))\n\n\n\n\n\n\n\n\nHIIR dose response\n\nggplot()+\n      geom_hline(yintercept = c(-0.3,0.3),linetype=\"dashed\",col=\"gray70\")+\n    geom_hline(yintercept = 0,col=\"gray7\")+\n    geom_vline(xintercept = c(-1,1),linetype=\"dashed\",col=\"gray70\")+\n    geom_vline(xintercept = 0,linetype=\"dashed\",col=\"gray7\")+\n    geom_point(data = residuals[grepl(\"HI-IR\",DV)&!variable==\"Week\",],alpha=.4,size=1,\n           mapping = aes(x=IV_value,y=DV_value),\n           colour=\"#4e94ce\")+\n    geom_ribbon(pltDat[grepl(\"HI-IR\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate,ymin=.lower_ci,ymax=.upper_ci),\n       alpha=.5,col=NA)+\n    geom_path(pltDat[grepl(\"HI-IR\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate))+\n  facet_grid(rows = vars(DV),cols = vars(variable),\n             labeller = label_parsed)+\n    ylim(c(-1.2,1.2))+\n    labs(x = \"Within participant scaled load\",\n       y = \"Between participant scaled response\")+\n    theme(legend.position = \"bottom\",\n          text=element_text(family = \"Times\"),\n          panel.grid = element_blank(),\n        panel.background = element_rect(fill = NA,colour=\"gray30\"))\n\n\n\n\n\n\n\n\nCF - SMFT dose response\n\nggplot()+\n      geom_hline(yintercept = c(-0.3,0.3),linetype=\"dashed\",col=\"gray70\")+\n    geom_hline(yintercept = 0,col=\"gray7\")+\n    geom_vline(xintercept = c(-1,1),linetype=\"dashed\",col=\"gray70\")+\n    geom_vline(xintercept = 0,linetype=\"dashed\",col=\"gray7\")+\n    geom_point(data = residuals[grepl(\"CF-SMFT\",DV)&!variable==\"Week\",],alpha=.3,size=1,\n           mapping = aes(x=IV_value,y=DV_value),\n           colour=\"#4e94ce\")+\n    geom_ribbon(pltDat[grepl(\"CF-SMFT\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate,ymin=.lower_ci,ymax=.upper_ci),\n       alpha=.5,col=NA)+\n    geom_path(pltDat[grepl(\"CF-SMFT\",DV)&!variable==\"Week\",],\n       mapping=aes(value,.estimate))+\n  facet_grid(rows = vars(DV),cols = vars(variable),\n             labeller = label_parsed)+\n   #  facet_wrap(~DV+variable,nrow=3,\n  #           labeller = label_parsed)+\n   # theme_tufte()+\n    ylim(c(-1.2,1.2))+\n    labs(x = \"Within participant scaled load\",\n       y = \"Between participant scaled response\")+\n    theme(legend.position = \"bottom\",\n          text=element_text(family = \"Times\"),\n          panel.grid = element_blank(),\n        panel.background = element_rect(fill = NA,colour=\"gray30\"))"
  },
  {
    "objectID": "index.html#temporal-effects",
    "href": "index.html#temporal-effects",
    "title": "Additional materials",
    "section": "Temporal effects",
    "text": "Temporal effects\n\ntemp_sum= edf_bind|&gt;\n    fsubset(grepl(\"Week\",contrast))|&gt;\n    fsubset(!grepl(\"ID\",contrast))|&gt;\n    fsubset(edf_pvalue&lt;0.01)\n\n\ntemp_sum|&gt;\n  kableExtra::kable()|&gt;\n      add_header_above(c(\"\",\"\",\"gam summary\" = 3))|&gt;\n  kable_paper()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngam summary\n\n\n\nDV\ncontrast\nedf\nF\nedf_pvalue\n\n\n\n\nZscr_BT_JHIM.mx\nWeek\n5.674\n57.164\n0.000\n\n\nZscr_BT_JHIM.mx\nWeek\n2.235\n19.037\n0.000\n\n\nZscr_BT_FZVmx\nWeek\n1.694\n21.843\n0.000\n\n\nZscr_BT_FTCT.mx\nWeek\n4.827\n21.304\n0.000\n\n\nZscr_BT_FTCT.mx\nWeek\n1.752\n10.927\n0.001\n\n\nZscr_BT_tm_CV_SMF1\nWeek\n8.332\n18.306\n0.000\n\n\nZscr_BT_tm_CV_SMF1\nWeek\n8.336\n33.001\n0.000\n\n\nZscr_BT_mu.vel_CV_SMF1\nWeek\n8.749\n58.122\n0.000\n\n\nZscr_BT_mu.vel_CV_SMF1\nWeek\n8.407\n38.862\n0.000\n\n\nZscr_BT_logAdj_pl.up\nWeek\n4.290\n5.747\n0.000\n\n\nZscr_BT_logAdj_pl.side\nWeek\n4.030\n2.963\n0.002\n\n\nZscr_BT_HRmu_perc\nWeek\n2.701\n20.203\n0.000\n\n\nZscr_BT_pl.fwd_CV_SMR1\nWeek\n2.098\n12.668\n0.000\n\n\nZscr_BT_pl.side_CV_SMR1\nWeek\n2.075\n12.461\n0.000\n\n\nZscr_BT_pl.side_CV_SMR1\nWeek\n2.490\n6.564\n0.000\n\n\n\n\n\n\n\n\ntemporalFig=ggplot(pltDat[grepl(\"Week\",.smooth)&!DV==\"HI-IR~Vel\",],\n       aes(value,.estimate,\n           ymin=.lower_ci,\n           ymax=.upper_ci,\n           fill=.smooth))+\n  annotate(geom = \"rect\",xmin = -Inf,xmax=Inf,ymin = -0.3,ymax=0.3,\n           alpha=.2)+\n  geom_hline(yintercept = c(-0.3,0.3),size=0.1)+\n  geom_ribbon(alpha=.5,col=\"white\")+\n  geom_path()+\n  ylim(c(-1,1))+\n  labs(y=\"Between athlete scaled Estimate\",x=\"Week\")+\n  facet_wrap(~DV,labeller = label_parsed)+\n  theme(panel.background = element_rect(fill = NA,colour=\"black\"),\n        panel.grid = element_blank(),\n        legend.position = \"top\",\n        text = element_text(family = \"Times\"))\n\n\nHIIRvel_temp &lt;-ggplot(pltDat[grepl(\"Week\",.smooth)&DV==\"HI-IR~Vel\",],\n       aes(value,.estimate,\n           ymin=.lower_ci,\n           ymax=.upper_ci,\n           fill=.smooth))+\n  annotate(geom = \"rect\",xmin = -Inf,xmax=Inf,ymin = -0.3,ymax=0.3,\n           alpha=.2)+\n  geom_ribbon(alpha=.5)+\n  geom_path()+\n  ylim(c(-3,3))+\n  labs(y=\"Between athlete scaled Estimate\",x=\"Week\")+\n  facet_wrap(~DV,labeller = label_parsed)+\n  theme(panel.background = element_rect(fill = NA,colour=\"black\"),\n        panel.grid = element_blank(),\n        legend.position = \"top\",\n        text = element_text(family = \"Times\"))\n\n\nggpubr::ggarrange(temporalFig,HIIRvel_temp,widths = c(0.7,0.3),common.legend = T)"
  }
]